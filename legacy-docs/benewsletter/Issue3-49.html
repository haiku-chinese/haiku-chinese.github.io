<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<!-- Mirrored from www.haiku-os.org/legacy-docs/benewsletter/Issue3-49.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 05 Aug 2021 01:42:03 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Be Newsletters - Volume 3: 1998</title><link rel="stylesheet" href="be_newsletter.css" type="text/css" media="all" /><link rel="shortcut icon" type="image/vnd.microsoft.icon" href="images/favicon.ico" /><!--[if IE]>
    <link rel="stylesheet" type="text/css" href="be_newsletter_ie.css" />
    <![endif]--><meta name="generator" content="DocBook XSL Stylesheets V1.73.2" /><link rel="start" href="index-2.html" title="Be Newsletters" /><link rel="up" href="volume3.html" title="Volume 3: 1998" /><link rel="prev" href="Issue3-48.html" title="Issue 3-48, December 2, 1998" /><link rel="next" href="Issue3-50.html" title="Issue 3-50, December 16, 1998" /></head><body><div id="header"><div id="headerT"><div id="headerTL"><a accesskey="p" href="Issue3-48.html" title="Issue 3-48, December 2, 1998"><img src="images/navigation/prev.png" alt="Prev" /></a> <a accesskey="u" href="volume3.html" title="Volume 3: 1998"><img src="images/navigation/up.png" alt="Up" /></a> <a accesskey="n" href="Issue3-50.html" title="Issue 3-50, December 16, 1998"><img src="images/navigation/next.png" alt="Next" /></a></div><div id="headerTR"><div id="navigpeople"><a href="../../index.html"><img src="images/People_24.png" alt="haiku-os.org" title="Visit The Haiku Website" /></a></div><div class="navighome" title="Home"><a accesskey="h" href="index-2.html"><img src="images/navigation/home.png" alt="Home" /></a></div><div class="navigboxed" id="naviglang" title="English">en</div></div><div id="headerTC">Be Newsletters - Volume 3: 1998</div></div><div id="headerB">Prev: <a href="Issue3-48.html">Issue 3-48, December 2, 1998</a>  Up: <a href="volume3.html">Volume 3: 1998</a>  Next: <a href="Issue3-50.html">Issue 3-50, December 16, 1998</a></div><hr /></div><div class="article"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h2 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="Issue3-49"></a>Issue 3-49, December 9, 1998</h2></div></div></div><div class="sect1"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h2 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="Engineering3-49"></a>Be Engineering Insights: Creating an Internet Search Engine</h2></div><div xmlns:d="http://docbook.org/ns/docbook"><span xmlns="http://www.w3.org/1999/xhtml" class="author">By <span class="firstname">Russ</span> <span class="surname">McMahon</span></span></div></div></div><p>
The most rewarding thing for me as a contributor to the Be Developer
Newsletter is the chance to explore applications and technologies that
aren't on any schedule or project master plan. It's an opportunity to
write code just for the fun of it, and share the knowledge and experience
with others. One long-time interest of mine is Internet search engines
and Internet robots. I thought it would be cool to scan the Web to
retrieve particular items and then process the returns using my own rules
and conditions. I know there are services out there to do just that, but
I wanted something that I could control, so for this article I built a
simple Internet search engine.
</p><p>
I'd like to thank Benoît Schillings for his article
<a class="xref" href="Issue3-40.html#Engineering3-40" title="Be Engineering Insights: Mining The Net... (Part 1 of N)">Be Engineering Insights: Mining The Net... (Part 1 of N)</a>.
In it, Benoît lays out a "site_getter" class and goes into detail about
the Internet search process. I also want to thank James Clark for his
awesome <acronym class="acronym" title="Standard Generalized Markup Language">SGML</acronym>
parser - normalizer NSGMLS. These tools are definitely worth
checking out.
</p><p>
Currently, most people use large scale search engines such as Lycos,
Yahoo, Alta Vista, and others. These have huge databases that hold Web
links and other information that users can access. Robots—also called
spiders—roam the Web and feed the local databases, trying to keep an
up to date representation of the Web. I wanted to call my project "the
embryonic beginnings of a Web 'bot," but I can't, because as you'll see
below, my sample engine is really a meta-search engine.
</p><p>
Meta-search engines query primary search engines (like those named above)
in order to gather query results. They maintain no local database of
their own and often do pre- and post-processing on the query and returned
results. A good example of a meta-search engine is MetaCrawler
<a class="ulink" href="http://www.metacrawler.com/">http://www.metacrawler.com/</a>; it can span multiple search engines and
claims to provide users with a more consistent interface. Another popular
meta-search engine is Sherlock <a class="ulink" href="http://www.apple.com/sherlock/">http://www.apple.com/sherlock/</a>;. Sherlock
ships with Mac OS 8.5, and replaces the system Find application as a
generalized search program. In addition to local searches, it does
Web-based searches.
</p><p>
Both Sherlock and MetaCrawler can span multiple search engines, but
unlike MetaCrawler, Sherlock processes the query results locally through
configurable plug-ins. Well heck, if all a meta-search engine needs to do
is contact the main search engines, and have them return the goods, that
seems easy enough—so it's time to start coding.
</p><p>
In the sample below, a
<acronym class="acronym" title="Transmission Control Protocol">TCP</acronym>
connection is made to <a class="ulink" href="http://www.altavista.com/">http://www.altavista.com</a>,
server port 80 (HTTP). I send a GET request with the path of the
<acronym class="acronym" title="Common Gateway Interface">CGI</acronym>
script to execute, and the parameters to pass to the script. The main
parameter of interest is the <code class="varname">search</code>
keyword, in this case "primus"—a
locally popular rock band. I end the request with HTTP/1.0 and a blank
line to terminate the request. I receive back from the server an
<acronym class="acronym">HTML</acronym>
page with a list of hits matching "primus." The page is sent to standard
out.
</p><pre class="programlisting c">
#include &lt;stdio.h&gt;
#include &lt;socket.h&gt;
#include &lt;netdb.h&gt;
#include &lt;string.h&gt;
#include &lt;iostream.h&gt;

class <code class="classname">mysearch</code>
{
public:
  <code class="methodname">mysearch</code>();
};

<code class="classname">mysearch</code>::<code class="methodname">mysearch</code>()
{
  <span class="type">int</span> <code class="varname">sd</code>;
  <span class="type">char</span> <code class="varname">buf</code>[<code class="constant">BUFSIZ</code>+1];

  <span class="comment">// Resolve Host name to IP address</span>
  struct <span class="type">in_addr **</span><code class="varname">pptr</code>;
  struct <span class="type">hostent *</span><code class="varname">hp</code>;

  <code class="varname">hp</code> = <code class="function">gethostbyname</code>("www.altavista.com");
  <code class="varname">pptr</code> = (struct <span class="type">in_addr**</span>)<code class="varname">hp</code>-&gt;<code class="varname">h_addr_list</code>;

  <span class="comment">// Server side socket</span>
  struct <span class="type">sockaddr_in</span> <code class="varname">dest</code>;
  <code class="function">memset</code>(&amp;<code class="varname">dest</code>,0,sizeof(<code class="varname">dest</code>));
  <code class="varname">dest</code>.<code class="varname">sin_family</code>=<code class="constant">AF_INET</code>;
  <code class="function">memcpy</code>(&amp;<code class="varname">dest</code>.<code class="varname">sin_addr</code>, *<code class="varname">pptr</code>, sizeof(struct <span class="type">in_addr</span>));
  <code class="varname">dest</code>.<code class="varname">sin_port</code>=<code class="function">htons</code>(80);

  <code class="varname">sd</code> = socket(<code class="constant">AF_INET</code>, <code class="constant">SOCK_STREAM</code>, 0);
  <code class="function">connect</code>(<code class="varname">sd</code>, (<span class="type">sockaddr*</span>)&amp;<code class="varname">dest</code>, <code class="function">sizeof</code>(<code class="varname">dest</code>));

  <span class="comment">// Blank line terminates HTTP request</span>
  <code class="function">sprintf</code>(<code class="varname">buf</code>,
    "GET /cgi- bin/query?pg=q&amp;kl=XX&amp;q=primus&amp;search=Search HTTP/1.0\n\n");
  <code class="function">send</code>(<code class="varname">sd</code>, <code class="varname">buf</code>, strlen(<code class="varname">buf</code>), 0);

  while (<code class="function">recv</code>(<code class="varname">sd</code>, <code class="varname">buf</code>, sizeof(<code class="varname">buf</code>), 0) &gt; 0)
    cout &lt;&lt; <code class="varname">buf</code>;
}

int main()
{
  <code class="classname">mysearch</code> <code class="varname">mysrch</code>;

  <code class="function">exit</code>(<code class="constant">EXIT_SUCCESS</code>);
}
</pre><p>
Why do it this way? Since searching and filtering tasks are quite
disparate in nature, I've put the search mechanism in one binary and the
query parser in another. I hope this makes the basic operations clearer,
and easier to follow. I use standard in and out to communicate between
the binaries. I haven't tried to make this robust or of production
quality, as the code serves only to demonstrate my topic. For the search
engine, much of the code is just getting a client connection set up, and
sending and receiving
<acronym class="acronym" title="HyperText Transport Protocol">HTTP</acronym>
data. The calls <code class="function">gethostbyname()</code>,
<code class="function">socket()</code>,
<code class="function">connect()</code>, <code class="function">send()</code>,
<code class="function">recv()</code> are all part of the
<acronym class="acronym" title="Berkeley Software Distribution">BSD</acronym> sockets API and are
similar across socket-based TCP/IP clients, so I hope they're not overly
distracting.
</p><p>
The above sample goes out to Alta Vista and looks for "primus." However,
it's easy to query other search engines as well. Just change the host
name, the <acronym class="acronym">CGI</acronym> path, and the parameter string. For example:
</p><p>
To search using Alta Vista:
</p><p>
Host Name: www.altavista.com
</p><p>
Parameters: /cgi-bin/query?pg=q&amp;kl=XX&amp;q=primus&amp;search=Search
</p><p>
To search using Excite:
</p><p>
Host Name: search.excite.com
</p><p>
Parameters: /search.gw?search=beegees
</p><p>
To search using Yahoo:
</p><p>
Host Name: search.yahoo.com
</p><p>
Parameters: /bin/search?search=beegees
</p><p>
Notice that I changed the Excite and Yahoo queries to search for
"beegees" rather than "primus." To query using other search engines I
haven't listed, such as Infoseek or Lycos, go the site with your browser
and enter your search keyword, then look at the
<acronym class="acronym" title="Uniform Resource Locator">URL</acronym> that is sent to sent
the Web server (in the location field at the top part of the browser
window). It should be easy to see what the host name and the
<acronym class="acronym">CGI</acronym>
parameters. are.
</p><p>
Be aware that there are several ways to send parameters back to Web
servers; if the simple method described above doesn't work, a deeper
understanding of <acronym class="acronym">CGI</acronym> and <acronym class="acronym">HTTP</acronym> may be
required. Dumping the <acronym class="acronym">HTML</acronym> page as
text is also a great way to see what's going on. Another way to
understand how <acronym class="acronym">CGI</acronym> and HTTP work is to set a Web server such as Apache
and write some scripts and forms. I recommend doing this before you use
the samples and blast away at the main search services.
</p><p>
If the query was successful an <acronym class="acronym">HTML</acronym> page listing the search results is
returned. To confirm that things are working, you can save the page to a
file and then open it in the browser. It should appear just as if the
browser had launched the query.
</p><p>
Now we're at the heart of things, and it's time to get at the goods! The
problem with this phase is that it's very application specific; what I'm
after may not be what you're after. Also, each search site has its own
results format, which may even change from query to query. Sherlock uses
pattern matching on the returned <acronym class="acronym">HTML</acronym> document to get at items of
interest. OK, but we can do better. I use James Clark's <acronym class="acronym">NSGMLS</acronym>
application to transform the document to a simpler and more rigid format
called <acronym class="acronym">ESIS</acronym> (Element Structure Information Set). The <acronym class="acronym">ESIS</acronym> format makes
getting at <acronym class="acronym">HTML</acronym> elements easy. <acronym class="acronym">NSGMLS</acronym> is a command line utility that uses
James's SP library to parse <acronym class="acronym">SGML</acronym> and also <acronym class="acronym">HTML</acronym> and
<acronym class="acronym" title="eXtensible Markup Language">XML</acronym>. James provides
nice <acronym class="acronym">HTML</acronym> documentation and sources for his parse utilities at
<a class="ulink" href="http://www.jclark.com/sp.html">http://www.jclark.com/sp.html</a>. The port to BeOS was trivial. For
example, the following <acronym class="acronym">HTML</acronym> document is transformed to
<acronym class="acronym">ESIS</acronym> using <acronym class="acronym">NSGMLS</acronym>:
</p><pre class="programlisting html">
&lt;html&gt;
&lt;body&gt;Your rock candy
&lt;/body&gt;
&lt;/html&gt;
</pre><p>
In <acronym class="acronym">ESIS</acronym> every element is on a separate line, and the first character on
the line is known as the command. The command can be used to decide how
to parse the line. In this simple sample that's no big deal, but results
returned from the search engines are more complex.
</p><pre class="screen">
(HTML
(BODY
-Your rock candy
)BODY
)HTML
</pre><p>
Now we're getting somewhere. If we run the search engine and pipe the
output to <acronym class="acronym">NSGMLS</acronym>, the <acronym class="acronym">ESIS</acronym> syntax will be sent to standard out. However,
it's the whole page, and I just want to get at specific elements within
it. Time to slap down a bit more code.
</p><pre class="programlisting cpp">
#include &lt;stdio.h&gt;
#include &lt;iostream.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;

class <code class="classname">myfilter</code>
{
public:
  <code class="methodname">myfilter</code>();


  friend <span class="type">istream&amp;</span> <code class="methodname">operator &gt;&gt;</code> (<span class="type">istream&amp;</span> <code class="parameter">s</code>, <span class="type"><code class="classname">myfilter</code>&amp;</span> <code class="parameter">myftlr</code>);

private:
  <span class="type">int</span> <code class="methodname">GetNextFieldStr</code>(<span class="type">char*</span> <code class="parameter">instring</code>, <span class="type">char*</span> <code class="parameter">outstring</code>);

};

<code class="classname">myfilter</code>::<code class="methodname">myfilter</code>()
{
}

<span class="type">istream&amp;</span> <code class="methodname">operator &gt;&gt;</code> (<span class="type">istream&amp;</span> <code class="parameter">s</code>, <span class="type">myfilter&amp;</span> <code class="parameter">myfltr</code>)
{
  <span class="type">char</span> <code class="varname">buf</code>[<code class="constant">BUFSIZ</code>+1];
  <span class="type">char</span> <code class="varname">cmpbuf</code>[<code class="constant">BUFSIZ</code>+1];

  while (<code class="parameter">s</code>){
    <code class="parameter">s</code>.<code class="function">getline</code>(<code class="varname">buf</code>, sizeof(<code class="varname">buf</code>));

    <span class="comment">// Parse the lines using ESIS syntax</span>
    if (<code class="varname">buf</code>[0] == 'A'){
      <code class="parameter">myfltr</code>.<code class="methodname">GetNextFieldStr</code>(<code class="varname">buf</code>, <code class="varname">cmpbuf</code>);
      if (<code class="function">strcmp</code>(<code class="varname">cmpbuf</code>, "AHREF") != 0)
        continue;

      <code class="parameter">myfltr</code>.<code class="methodname">GetNextFieldStr</code>(<code class="varname">buf</code>, <code class="varname">cmpbuf</code>);
      if (<code class="function">strcmp</code>(<code class="varname">cmpbuf</code>, "CDATA") != 0)
        continue;

      <code class="parameter">myfltr</code>.<code class="methodname">GetNextFieldStr</code>(<code class="varname">buf</code>, <code class="varname">cmpbuf</code>);
      if (<code class="function">strncmp</code>(<code class="varname">cmpbuf</code>, "http", 4) != 0)
        continue;

      <span class="comment">// Found something of interest</span>
        cout &lt;&lt; <code class="varname">buf</code> &lt;&lt; endl;
    }
  }

  return <code class="parameter">s</code>;
}

<span class="type">int</span>
<code class="classname">myfilter</code>::<code class="methodname">GetNextFieldStr</code>(<span class="type">char*</span> <code class="parameter">instring</code>, <span class="type">char*</span> <code class="parameter">outstring</code>)
{
  <span class="type">char*</span> ptr;
  <span class="type">char*</span> ptr1;
  <span class="type">char*</span> ptr2;

  <code class="varname">ptr</code> = <code class="parameter">instring</code>;

  if((<code class="varname">ptr1</code> = strchr(<code class="varname">ptr</code>, ' ')) == <code class="constant">NULL</code>){
    <code class="function">strcpy</code>(<code class="parameter">outstring</code>, <code class="parameter">instring</code>);
    return (0);
  }

  *<code class="varname">ptr1</code> = '\0';
  <code class="varname">ptr2</code> = ++<code class="varname">ptr1</code>;

  for(<span class="type">int</span> <code class="varname">n</code> = <code class="constant">BUFSIZ</code>; <code class="varname">n</code> &gt;= 0; <code class="varname">n</code>--){
    <code class="varname">ptr1</code>--;
    if (*<code class="varname">ptr1</code> == ' ')
      *<code class="varname">ptr1</code> = '\0';
    else
      break;
  }

  <code class="function">strcpy</code>(<code class="parameter">outstring</code>, <code class="varname">ptr</code>);
  <code class="function">strcpy</code>(<code class="parameter">instring</code>, <code class="varname">ptr2</code>);

  return (1);
}

<span class="type">int</span> <code class="function">main</code>()
{
  <code class="classname">myfilter</code> <code class="varname">myfltr</code>;

  <span class="comment">// Overloaded extraction operator</span>
  cin &gt;&gt; <code class="varname">myfltr</code>;

  <code class="function">exit</code>(<code class="constant">EXIT_SUCCESS</code>);
}
</pre><p>
The sample above goes through the page and grabs <acronym class="acronym">URL</acronym>s beginning with
http. The <acronym class="acronym">URL</acronym>s are located using the "AHREF CDATA" syntax of <acronym class="acronym">ESIS</acronym>. So if
the search engine binary is called <code class="command">mysearch</code>, and the filter above is
called <code class="command">myfilter</code>, then after running the following, only <acronym class="acronym">URL</acronym>s starting
with http will be sent to standard out.
</p><pre class="screen">
$ mysearch | nsgmls | myfilter
</pre><p>
I know by looking at the <acronym class="acronym">URL</acronym>s outputted that further filtering is needed
to really nail down the "primus" search. This should be easy: I'll just
look at the <acronym class="acronym">ESIS</acronym> output and add some more parsing code to the filter
operation.
</p><p>
I hope you can see from these samples that there's a world of
possibilities to explore. Once <acronym class="acronym">URL</acronym> links are returned, they can be
further filtered to really customize the results of the query. Also, I go
after only http <acronym class="acronym">URL</acronym>s, but within the page returned from the main search
engines there's often hit-rating information and other goodies. I'd like
to turn the command line utilities into real applications, and search the
different engines in parallel using threads, and cross- reference the
results. It would also be great to plug the meta-search engine into Be's
Find application, and turn the results into <span class="application">NetPositive</span> Bookmarks. I
didn't make it quite that far in this article, but there's always next
time.
</p></div><hr class="pagebreak" /><div class="sect1"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h2 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="Engineering3-49-2"></a>Be Engineering Insights: Something Fishy</h2></div><div xmlns:d="http://docbook.org/ns/docbook"><span xmlns="http://www.w3.org/1999/xhtml" class="author">By <span class="firstname">Adam</span> <span class="surname">Haberlach</span></span></div></div></div><p>
I recently implemented a client for the "Distributed Fish Protocol"
(DFP). The protocol defines a common environment for transferring simple
data objects ("fish") between machines ("tanks"). The protocol was
designed as a demonstration of some operating systems created by members
of the <acronym class="acronym">ACM</acronym> chapter at <acronym class="acronym">UIUC</acronym>. The entire system is extremely small; the
whole thing can be implemented using only broadcast <acronym class="acronym">UDP</acronym> packets. Because
<acronym class="acronym">UDP</acronym> is somewhat unreliable, steps are taken to make sure that fish are
not lost. For relevant <acronym class="acronym" title="Request For Comment">RFC</acronym>s, check out
</p><p>
<a class="ulink" href="http://www.acm.uiuc.edu/sigops/eoh98/dfp/fish.html">http://www.acm.uiuc.edu/sigops/eoh98/dfp/fish.html</a>
</p><p>
To handle incoming packets, my <acronym class="acronym">DFP</acronym> client implementation
defines the "FishPortal" class. A
<code class="classname">FishPortal</code> object binds and listens to a
<acronym class="acronym">UDP</acronym> port (in a separate thread). When it gets a Fish
Protocol Packet, the packet is repackaged as a
<code class="classname">BMessage</code>, which is sent to and handled by the
client's <code class="classname">BWindow</code> object.
</p><p>
There are two types of messages that need to be handled: The "Tank"
message lets a tank locate its neighbors, and the "Transfer" message lets
a tank transfer a fish to a neighboring tank.
</p><div class="sect2"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h3 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="id764902"></a>The Location Message</h3></div></div></div><p>
A tank lives in a 256x256 tank array called "TankSpace." To see if its
neighbors are "alive", a tank broadcasts a <code class="command">PING</code> message to its nearest
neighbors in TankSpace (top, bottom, left, right), and then listens for a
responsive <code class="command">PONG</code>. In my <acronym class="acronym">DFP</acronym> client, I use the new
<code class="classname">BMessageRunner</code> class to
regularly broadcast the <code class="command">PING</code> message. Before every
<code class="command">PING</code>, my <code class="classname">FishPortal</code>
object marks all four neighbors as dead, and then marks them alive if
they respond. (A more complex system could be a bit smarter about
tracking the identity and states of the other tanks.)
</p><p>
Whenever the status of a neighboring tanks changes, a <code class="classname">BMessage</code> is sent so
that the client can update any indicators it uses. My client displays
green and red dots to indicate the states of the other tanks. Still
another neat thing for a client to do would be to recognize when it is in
the same space as another tank and move itself to another location to
avoid tank collisions.
</p></div><div class="sect2"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h3 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="id764961"></a>The Transfer Message</h3></div></div></div><p>
When a fish swims to the edge of a tank, the client checks to make sure
the neighboring tank in that direction is alive, and, if it is, it sends
the tank a <code class="command">SEND_FISH</code> message that includes information about the relevant
fish. The receiver responds with an <code class="command">ACK_FISH</code> to acknowledge that it will
take the fish, or a <code class="command">NACK_FISH</code> to refuse. The fish supplier responds with
a final <code class="command">SYNC_FISH</code> packet, which formally passes responsibility for the
fish to the receiving tank.
</p><p>
If a neighboring tanks isn't alive, the fish is thrown back in the same
tank and swims off in a new direction. Either way, the client need only
send a message to the <code class="classname">FishPortal</code>, which takes care of all the details of
passing the fish along or throwing it back in the tank.
</p><p>
The FishPortal class also handles a list of "pending" fish, since fish
spend some time in limbo while the fish-passing messages are being
handled. Currently, there's no provision for other clients denying
reception (through a <code class="command">NACK_FISH</code>), or not responding. A smarter client
would include a time-out system to make sure that pending fish don't get
lost between the display layer and the network.
</p><p>
Note that I didn't spend much time fine-tuning the display. As a result,
my fish swim backwards and flicker.
</p><p>
I know of one bug in the code, and I'm sure I will get lots of mail
pointing out the ones that got away. If anyone out there has any
interesting additions or suggestions (or even new clients), I'm always
interested.
</p><p>
The supplied client defaults to a tank located at (3,3). To specify a
different location, use the command-line arguments -x &lt;int&gt; and -y &lt;int&gt;.
For example, if you have two machines on the same network, just starting
a client on one machine with the default location and the other with the
line "Tank -x 4 -y 3" should put them next to each other in TankSpace.
</p></div></div><hr class="pagebreak" /><div class="sect1"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h2 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="DevWorkshop3-49"></a>Developers' Workshop: The Refrigerator Question</h2></div><div xmlns:d="http://docbook.org/ns/docbook"><span xmlns="http://www.w3.org/1999/xhtml" class="author">By <span class="firstname">Eric</span> <span class="surname">Shepherd</span></span></div></div></div><p>
Of all the functions the BeOS provides to programmers, one of the least
understood and most widely debated is <code class="function">is_computer_on()</code>. Documentation has
been sketchy, and developers have debated the best use for this function.
This week, we'll investigate <code class="function">is_computer_on()</code> in depth.
</p><p>
Some developers claim that this function always returns 1, and say that
it's a sham. They say their tests have produced significant empirical
evidence to this effect. Others offer circumstantial evidence, such as
"programs can't run when the computer's off," which doesn't really
explain anything.
</p><p>
This is a lot like trying to figure out if the light stays on in the
refrigerator when you close the door. How can you be sure that
<code class="function">is_computer_on()</code> isn't returning some other value when the computer's off?
Let's look at a test program:
</p><pre class="programlisting">
#include &lt;OS.h&gt;
#include &lt;stdio.h&gt;

<span class="type">int</span> <code class="function">main</code>(void) {
  <span class="type">int</span> <code class="varname">i</code>;

  <code class="function">printf</code>("#     Result\n");
  <code class="function">printf</code>("----- ------\n");
  for (<code class="varname">i</code>=1;<code class="varname">i</code>&lt;=25;<code class="varname">i</code>++) {
    <code class="function">printf</code>("%-5d %ld\n", <code class="varname">i</code>, <code class="function">is_computer_on</code>());
  }
  return 0;
}
</pre><p>
If you run this program, you get the following output:
</p><pre class="screen">
#     Result
----- ------
1     1
2     1
3     1
4     1
5     1
6     1
7     1
8     1
9     1
10    1
(and so on)
</pre><p>
Now try running the program and shutting off your computer while it's
running. Unfortunately, <code class="function">printf()</code> doesn't work reliably in this case; you
don't see your output, because the computer's video hardware becomes
unreliable when turned off. You might try customizing this code to write
the output to disk, but unfortunately, hard drives also become unreliable
when power isn't applied to them throughout their operation. Networking
and serial ports likewise have a high failure rate when power is turned
off.
</p><p>
In other words, the empirical evidence is a little flimsy. Due to
failures beyond Be's control, test programs such as the one above can't
present their full results. I'm not saying that <code class="function">is_computer_on()</code> returns
some other value when the computer isn't running, but this is a prime
example of the difficulty encountered when testing a theory through code.
</p><p>
However, Be guarantees that <code class="function">is_computer_on()</code> will always return 1 if the
computer is running.
</p></div><hr class="pagebreak" /><div class="sect1"><div xmlns="" xmlns:d="http://docbook.org/ns/docbook" class="titlepage"><div><div xmlns:d="http://docbook.org/ns/docbook"><h2 xmlns="http://www.w3.org/1999/xhtml" class="title"><a id="Gassee3-49"></a>Developers Large and Small</h2></div><div xmlns:d="http://docbook.org/ns/docbook"><span xmlns="http://www.w3.org/1999/xhtml" class="author">By <span class="firstname">Jean-Louis</span> <span class="surname">Gassée</span></span></div></div></div><p>
As often, this column is in response to recurring discussions I've had or
witnessed, in person or electronically. Today's topic is what type of
developers we're looking for—a subject that appears to have been
re-energized by recent announcements around Release 4 and Comdex.
</p><p>
When major, "brand name" developers such as MGI or Steinberg announce
their support of the BeOS platform, what does it mean for emerging
developers who lack the resources and market muscle of more
well-established companies? Are we abandoning the little guy and cozying
up to the establishment?
</p><p>
I'll say at the outset that these questions address very real, permanent
issues. The need to give critical mass to the platform is one issue; the
threat of established developers muscling smaller ones out of the
ecosystem is another; and Be's role, if any, in maintaining balance in
the system yet another.
</p><p>
Meeting the first need—giving critical mass to the platform—causes
trouble and ambivalence. On one hand, seeing a major player on the
nascent platform is reassuring, since it legitimizes it and strengthens
the self-fulfilling prophecy: the platform will take because respectable,
established people believe it will. On the other hand, these established
companies may become ogres that devour fledgling developers. This is a
real issue, but it's only part of the story. The establishment may be
powerful, but it is also conservative. It rarely shows the most
innovation and is often muscle-bound.
</p><p>
A new platform is like a new musical instrument. You can transpose
existing music for it, or write new music that exploits its unique
expressive power. The saxophone, for example, solved two problems: it
provided better coupling and impedance between the reed and the air mass;
and the mechanics offered better, faster fingering and a wider range of
notes. You could play Bach fugues on a saxophone (rather nicely) or
explore the then-emerging genre of jazz.
</p><p>
Likewise, with a new operating system, you can write a PhotoShop clone,
or take a more innovative approach to image creation and processing. If
this sounds like "all you need to do to lose weight is eat less and
exercise more," my apologies. So instead of offering simplistic advice,
perhaps I should address what we can do. For one thing, we're already
working to make BeDepot an effective, inexpensive distribution channel
for Be developers. We still have much work to do, but our intent is
clear: this is equally open to all, this is a level playing field.
</p><p>
And then there is what we shouldn't do. I still remember the 1985 day
when Bill Gates threatened to stop developing applications for the
Macintosh if a certain software and its look and feel license wasn't
renewed. Apple's executive staff met and decided not to go along. One
dinner later, the license was renewed. We can only speculate what would
have happened if other developers had been allowed to take the room on
the Mac platform that Microsoft now occupies. The lesson in this story
for Be is that we know we shouldn't make decisions that limit innovation
and tie the platform.
</p></div></div><div id="footer"><hr /><div id="footerT">Prev: <a href="Issue3-48.html">Issue 3-48, December 2, 1998</a>  Up: <a href="volume3.html">Volume 3: 1998</a>  Next: <a href="Issue3-50.html">Issue 3-50, December 16, 1998</a> </div><div id="footerB"><div id="footerBL"><a href="Issue3-48.html" title="Issue 3-48, December 2, 1998"><img src="images/navigation/prev.png" alt="Prev" /></a> <a href="volume3.html" title="Volume 3: 1998"><img src="images/navigation/up.png" alt="Up" /></a> <a href="Issue3-50.html" title="Issue 3-50, December 16, 1998"><img src="images/navigation/next.png" alt="Next" /></a></div><div id="footerBR"><div><a href="../../index.html"><img src="images/People_24.png" alt="haiku-os.org" title="Visit The Haiku Website" /></a></div><div class="navighome" title="Home"><a accesskey="h" href="index-2.html"><img src="images/navigation/home.png" alt="Home" /></a></div></div><div id="footerBC"><a href="http://www.access-company.com/home.html" title="ACCESS Co."><img alt="Access Company" src="images/access_logo.png" /></a></div></div></div><div id="licenseFooter"><div id="licenseFooterBL"><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/" title="Creative Commons License"><img alt="Creative Commons License" style="border-width:0" src="../../../licensebuttons.net/l/by-nc-nd/3.0/88x31.png" /></a></div><div id="licenseFooterBR"><a href="LegalNotice.html">Legal Notice</a></div><div id="licenseFooterBC"><span id="licenseText">This work is licensed under a
          <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/3.0/">Creative
          Commons Attribution-Non commercial-No Derivative Works 3.0 License</a>.</span></div></div><!-- Fathom -->
<script>
(function(f, a, t, h, o, m){
	a[h]=a[h]||function(){
		(a[h].q=a[h].q||[]).push(arguments)
	};
	o=f.createElement('script'),
	m=f.getElementsByTagName('script')[0];
	o.async=1; o.src=t; o.id='fathom-script';
	m.parentNode.insertBefore(o,m)
})(document, window, '../../../metrics.haiku-os.org/tracker.js', 'fathom');
fathom('trackPageview');
</script>
<!-- / Fathom --></body>
<!-- Mirrored from www.haiku-os.org/legacy-docs/benewsletter/Issue3-49.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 05 Aug 2021 01:42:03 GMT -->
</html>
